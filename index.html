<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto">
    <link rel="stylesheet" type="text/css" href="./style.css">
    <script defer src="https://use.fontawesome.com/releases/v5.6.3/js/regular.js" integrity="sha384-V+AkgA1cZ+p3DRK63AHCaXvO68V7B5eHoxl7QVN21zftbkFn/sGAIVR7vmQL3Zhp" crossorigin="anonymous"></script>
    <script defer src="https://use.fontawesome.com/releases/v5.6.3/js/brands.js" integrity="sha384-VLgz+MgaFCnsFLiBwE3ItNouuqbWV2ZnIqfsA6QRHksEAQfgbcoaQ4PP0ZeS0zS5" crossorigin="anonymous"></script>
    <script defer src="https://use.fontawesome.com/releases/v5.6.3/js/fontawesome.js" integrity="sha384-treYPdjUrP4rW5q82SnECO7TPVAz4bpas16yuE9F5o7CeBn2YYw1yr5oC8s8Mf8t" crossorigin="anonymous"></script>
    <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
    <link rel="manifest" href="/site.webmanifest">
    <title>Motion Policy Networks</title>
  </head>
  <body>
    <div id="container">
      <div class="banner">
        <div class="banner-text">
          <h1 class="title">Motion Policy Networks</h1>
          <h2 class="author">
            <a href="https://fishbotics.com" target="_blank">Adam&nbsp;Fishman</a><sup>1,2</sup>,
            <a href="http://adithyamurali.com/" target="_blank">Adithyavairan&nbsp;Murali</a><sup>2</sup>,
            <a href="https://clemense.github.io/" target="_blank">Clemens&nbsp;Eppner</a><sup>2</sup>,
          </h2>
          <h2 class="author">
            <a href="http://www.gnarlydesign.io/" target="_blank">Bryan&nbsp;Peele</a><sup>2</sup>,
            <a href="https://homes.cs.washington.edu/~bboots/" target="_blank">Byron&nbsp;Boots</a><sup>1,2</sup>,
            <a href="https://https://homes.cs.washington.edu/~fox/" target="_blank">Dieter&nbsp;Fox</a><sup>1,2</sup>
          </h2>
          <p class="institutions"><sup>1</sup>University&nbsp;of&nbsp;Washington, <sup>2</sup>NVIDIA</p>
        </div>
      </div>
      <div id="links">
        <!-- <a class="link-button" href="" target="_blank">Paper</a> -->
        <a class="link-button" href="https://github.com/NVlabs/motion-policy-networks" target="_blank">Code</a>
        <a class="link-button" href="https://zenodo.org/record/7130512" target="_blank">Data</a>
      </div>
      <!--<div id="cover-image"></div>-->
      <div id="cover-wrapper">
        <img src="static/cover_split.png", alt="Motion Policy Networks are trained in sim and transfer to the real world" id="cover-image"></img>
      </div>
      <div class="line"></div>
      <div class="section">
        <h3>Abstract</h3>
        <p>Collision-free motion generation in unknown environments is a core building block for robot manipulation.
  Generating such motions is challenging due to multiple objectives; not only should the solutions be optimal, the motion generator itself must be fast enough for real-time performance and reliable enough for practical deployment.
  A wide variety of methods have been proposed ranging from local controllers to global planners, often being combined to offset their shortcomings. We present an end-to-end neural model called Motion Policy Networks (MπNets) to generate collision-free, smooth motion from just a single depth camera observation. MπNets are trained on over 3 million motion planning problems in over 500,000 environments.
  Our experiments show that MπNets are significantly faster than global planners while exhibiting the reactivity needed to deal with dynamic scenes. They are <em>46%</em> better than prior neural planners and more robust than local control policies. Despite being only trained in simulation, MπNets transfer well to the real robot with noisy partial point clouds.</p>
      </div>
      <div class="line"></div>
      <div class="section">
        <div class="video-wrapper">
          <div class="slide">
            <iframe class="youtube-video" src="https://www.youtube-nocookie.com/embed/hIWdQTq8AqQ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
          </div>
        </div>
        <div class="video-wrapper">
          <div class="slide">
            <iframe class="youtube-video" src="https://www.youtube-nocookie.com/embed/videoseries?list=PLTG3E67_prwtn6JpJ-ovDOvCFzEEvIXnH" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
          </div>
        </div>
        <div class="video-wrapper">
          <div class="slide">
            <iframe class="youtube-video" src="https://www.youtube-nocookie.com/embed/videoseries?list=PLTG3E67_prwsxVarSDkyWPSQBDrLU3JBM" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
          </div>
        </div>
      </div>
      <div class="line"></div>
      <div class="section" id="acknowledgements">
        <h3>Acknowledgements</h3>
        <p>We would like to thank the many people who have assisted in this research. In particular, we would like to thank Mike Skolones for supporting this research at NVIDIA,
          <a href="https://balakumar-s.github.io/">Balakumar Sundaralingam</a> and <a href="https://scholar.google.com/citations?user=TCYAoF8AAAAJ">Karl Van Wyk</a> for their help in evaluating MπNets and benchmarking it against STORM and Geometric Fabrics respectively; <a href="https://ankurhanda.github.io/">Ankur Handa</a>, <a href="https://chrisdxie.github.io/">Chris Xie</a>, <a href="https://cs.gmu.edu/~amousavi/">Arsalan Mousavian</a>, <a href="https://danielgordon10.github.io/">Daniel Gordon</a>, and <a href="https://aaronwalsman.com/">Aaron Walsman</a> for their ideas on network architecture, 3D machine learning, and training; <a href="https://scholar.google.com/citations?user=4bl7qAgAAAAJ">Nathan Ratliff</a> and <a href="https://cpaxton.github.io/">Chris Paxton</a> for their help in shaping the idea early-on; <a href="https://adityavk.com/">Aditya Vamsikrishna</a>, <a href="https://rosarioscalise.com/">Rosario Scalise</a>, <a href="https://www.brianhou.com/">Brian Hou</a>, and <a href="https://scholar.google.com/citations?user=NkjjAE8AAAAJ">Shohin Mukherjee</a> for their help in exploring ideas for the expert pipeline, <a href="https://scholar.google.ca/citations?user=zeS5UJEAAAAJ&hl=en">Jonathan Tremblay</a> for his visualization expertise, <a href="https://scholar.google.com/citations?user=48Y9F-YAAAAJ">Yu-Wei Chao</a> and <a href="https://yxyang.github.io/">Yuxiang Yang</a> for their help with using the Pybullet simulator, and <a href="https://www.linkedin.com/in/jennifermayer3/">Jennifer Mayer</a> for editing the final paper.
        </p>
      </div>
      <div class="section" id="footer">
      </div>
  </div>
  </body>
</html>
